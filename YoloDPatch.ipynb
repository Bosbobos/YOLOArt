{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Тесты генерации DPatch на YOLO",
   "id": "bdaa44e90946e520"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Вспомогательные методы",
   "id": "44a891c3507399b8"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-06T19:26:04.137168Z",
     "start_time": "2025-09-06T19:25:53.776565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from types import SimpleNamespace\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.loss import v8DetectionLoss\n",
    "from art.estimators.object_detection import PyTorchYolo\n",
    "from art.attacks.evasion import RobustDPatch\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from auxiliary import dataset_loader"
   ],
   "id": "95a7b82e00d2fd29",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T19:26:04.226140Z",
     "start_time": "2025-09-06T19:26:04.217566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "        'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "        'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "def get_image_with_boxes(img, labels, confidence=0.15):\n",
    "    text_size = 1\n",
    "    text_th = 3\n",
    "    rect_th = 2\n",
    "\n",
    "    boxes = labels.get('boxes')\n",
    "    pred_cls = labels.get('labels')\n",
    "    scores = labels.get('scores')\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] >= confidence:\n",
    "            cv2.rectangle(img, (int(boxes[i][0]), int(boxes[i][1])), (int(boxes[i][2]), int(boxes[i][3])),\n",
    "                          color=(0, 255, 0), thickness=rect_th)\n",
    "            cv2.putText(img, f\"{COCO_INSTANCE_CATEGORY_NAMES[pred_cls[i]]} {round(float(scores[i]), 2)}\",\n",
    "                        (int(boxes[i][0]), int(boxes[i][1]) - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, text_size, (0, 255, 0), thickness=text_th)\n",
    "\n",
    "    return img\n",
    "\n",
    "def show_predictions(patched_images, clean_images, patch_title, model, filename=None):\n",
    "    clean_preds = model.predict(clean_images)\n",
    "    patched_preds = model.predict(patched_images)\n",
    "\n",
    "    # Определяем количество строк (по одному ряду на каждую пару изображений)\n",
    "    n = len(patched_preds)\n",
    "    fig, axs = plt.subplots(n, 2, figsize=(9, 4 * n))\n",
    "\n",
    "    # Если только одно изображение, axs будет 1D, нужно преобразовать в 2D\n",
    "    if n == 1:\n",
    "        axs = axs.reshape(1, -1)\n",
    "\n",
    "    axs[0, 0].set_title(\"Original\")\n",
    "    axs[0, 1].set_title(patch_title)\n",
    "\n",
    "    for i in range(n):\n",
    "        # Оригинальное изображение с bounding box\n",
    "        im_orig = (clean_images[i]).transpose(1, 2, 0) * 255\n",
    "        im_orig_boxed = get_image_with_boxes(im_orig.copy(), clean_preds[i])\n",
    "        axs[i, 0].imshow(im_orig_boxed.astype(\"uint8\"))\n",
    "        axs[i, 0].axis(\"off\")\n",
    "\n",
    "        # Патченное изображение с bounding box\n",
    "        im_adv = (patched_images[i]).transpose(1, 2, 0) * 255\n",
    "        im_adv_boxed = get_image_with_boxes(im_adv.copy(), patched_preds[i])\n",
    "        axs[i, 1].imshow(im_adv_boxed.astype(\"uint8\"))\n",
    "        axs[i, 1].axis(\"off\")\n",
    "\n",
    "    if filename:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename)\n",
    "\n",
    "def save_patch(patch, filename):\n",
    "    # 1. Транспонируем в формат (H, W, C)\n",
    "    patch_hwc = np.transpose(patch, (1, 2, 0))\n",
    "\n",
    "    # 2. Нормализуем значения (если патч в [-1, 1] или [0, 1])\n",
    "    if patch_hwc.min() < 0:  # Предполагаем, что патч в [-1, 1]\n",
    "        patch_hwc = (patch_hwc + 1) * 127.5  # Масштабируем в [0, 255]\n",
    "    elif patch_hwc.max() <= 1:  # Если патч в [0, 1]\n",
    "        patch_hwc = patch_hwc * 255\n",
    "\n",
    "    # 3. Конвертируем в uint8 и сохраняем\n",
    "    patch_uint8 = patch_hwc.astype(np.uint8)\n",
    "    Image.fromarray(patch_uint8).save(filename)"
   ],
   "id": "63faa9e9fa34410f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Загрузка датасета",
   "id": "7a99902d7367b49c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T19:26:04.689431Z",
     "start_time": "2025-09-06T19:26:04.370422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conf = {\n",
    "    \"type\": \"images\",\n",
    "    \"path\": \"images_for_patch\"\n",
    "  }\n",
    "\n",
    "dataset = dataset_loader.DataFactory.load_dataset(conf)\n",
    "x = dataset.data\n",
    "y = dataset.target"
   ],
   "id": "8c75c0c5cf97e6e3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 22/22 [00:00<00:00, 86.23it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Создание модели для атаки",
   "id": "8e8852764658a3a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Адаптер\n",
    "\n",
    "Позволяет передать модель в ART, иначе будет ругаться"
   ],
   "id": "ac9e6fa669035986"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T19:26:04.776990Z",
     "start_time": "2025-09-06T19:26:04.767942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class YoloWrapper(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Обертка для модели YOLO, обеспечивающая совместимость с инструментами тестирования атак.\n",
    "\n",
    "    Поддерживает:\n",
    "    - Работу с моделями YOLO через ultralytics\n",
    "    - Расчет потерь для обучения\n",
    "    - Предсказание с возможностью постобработки\n",
    "\n",
    "    .. attribute:: orig_model\n",
    "        Оригинальная модель YOLO.\n",
    "        :type: YOLO\n",
    "\n",
    "    .. attribute:: classes\n",
    "        Список имен классов.\n",
    "        :type: list\n",
    "\n",
    "    .. attribute:: model\n",
    "        Внутренняя модель PyTorch.\n",
    "        :type: torch.nn.Module\n",
    "\n",
    "    .. attribute:: predict_count\n",
    "        Счетчик предсказаний.\n",
    "        :type: int\n",
    "\n",
    "    .. attribute:: loss_fn\n",
    "        Функция потерь для детекции.\n",
    "        :type: v8DetectionLoss\n",
    "    \"\"\"\n",
    "    def __init__(self, model, **kwargs):\n",
    "        \"\"\"\n",
    "        Инициализация обертки для YOLO модели.\n",
    "\n",
    "        :param model: Путь к модели или загруженная модель YOLO\n",
    "        :type model: str or YOLO\n",
    "        :param kwargs: Дополнительные параметры:\n",
    "                       - ``tal_topk``: количество топ-k для TAL (Task-Aligned Learning)\n",
    "                       - ``box``: коэффициент потерь для bounding box\n",
    "                       - ``cls``: коэффициент потерь для классификации\n",
    "                       - ``dfl``: коэффициент потерь для Distribution Focal Loss\n",
    "        :type kwargs: dict\n",
    "\n",
    "        .. note::\n",
    "            Модель автоматически переводится в режим оценки (eval), а её параметры замораживаются.\n",
    "            Функция потерь инициализируется с гиперпараметрами по умолчанию, которые можно переопределить.\n",
    "\n",
    "        Пример:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            wrapper = YoloWrapper(\"yolov8n.pt\", box=7.5, cls=0.5, dfl=1.5)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.orig_model = YOLO(model)\n",
    "        self.classes = list(self.orig_model.names.values())\n",
    "        self.model = self.orig_model.model\n",
    "        self.predict_count = 0\n",
    "\n",
    "        # Замораживаем параметры модели\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Инициализация функции потерь\n",
    "        self.loss_fn = v8DetectionLoss(self.model, tal_topk=kwargs.get(\"tal_topk\", 10))\n",
    "        self.loss_fn.hyp = SimpleNamespace(box=kwargs.get(\"box\", 7.5),\n",
    "                                           cls=kwargs.get(\"cls\", 0.5),\n",
    "                                           dfl=kwargs.get(\"dfl\", 1.5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        \"\"\"\n",
    "        Прямой проход модели.\n",
    "\n",
    "        :param x: Входной тензор изображения\n",
    "        :type x: torch.Tensor\n",
    "        :param targets: Тензор целей для обучения в формате ``[batch_idx, class, x1, y1, x2, y2]``\n",
    "        :type targets: torch.Tensor, optional\n",
    "        :return:\n",
    "            - В режиме обучения: словарь с компонентами потерь\n",
    "            - В режиме оценки: тензор предсказаний формы ``(n, 8400, 85)``\n",
    "        :rtype: dict or torch.Tensor\n",
    "\n",
    "        .. note::\n",
    "            В режиме обучения возвращается словарь с ключами:\n",
    "            - ``'loss_box'``: потери для координат bounding box\n",
    "            - ``'loss_cls'``: потери классификации\n",
    "            - ``'loss_dfl'``: Distribution Focal Loss\n",
    "\n",
    "        .. warning::\n",
    "            В режиме оценки выходной тензор имеет форму ``(n, 8400, 85)``, где:\n",
    "            - Первые 4 значения — координаты bbox (x1, y1, x2, y2)\n",
    "            - 5-е значение — objectness score\n",
    "            - Остальные — оценки классов\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            # Подготовка батча для расчета потерь\n",
    "            batch = {\n",
    "                \"batch_idx\": targets[:, 0].long(),\n",
    "                \"cls\": targets[:, 1].long(),\n",
    "                \"bboxes\": targets[:, 2:6].float(),\n",
    "            }\n",
    "            loss_total, loss_tensor = self.loss_fn(self.model(x), batch)\n",
    "\n",
    "            loss_dict = {\n",
    "                'loss_box': loss_total[0],  # Потери для bounding box\n",
    "                'loss_cls': loss_total[1],  # Потери классификации\n",
    "                'loss_dfl': loss_total[2]   # Distribution Focal Loss\n",
    "            }\n",
    "\n",
    "            return loss_dict\n",
    "\n",
    "        else:\n",
    "            # Получение предсказаний модели\n",
    "            pred = self.model(x)[0]  # (n, 84, 8400)\n",
    "\n",
    "            # Разделение на компоненты\n",
    "            boxes = pred[:, 0:4, :]  # Координаты bbox\n",
    "            class_scores = pred[:, 4:, :]  # Оценки классов\n",
    "\n",
    "            # Расчет objectness score как максимальной оценки класса\n",
    "            objectness, _ = class_scores.max(dim=1)  # (n, 8400)\n",
    "            objectness = objectness.unsqueeze(1)  # (n, 1, 8400)\n",
    "\n",
    "            # Объединение в формат [x1, y1, x2, y2, obj_score, class_scores...]\n",
    "            pred = torch.cat([\n",
    "                boxes,\n",
    "                objectness,\n",
    "                class_scores\n",
    "            ], dim=1)  # -> (n, 85, 8400)\n",
    "\n",
    "            # Транспонирование в формат [batch, 8400, 85]\n",
    "            pred = pred.permute(0, 2, 1)\n",
    "\n",
    "            return pred\n",
    "\n",
    "    def predict(self, x, postprocess=False):\n",
    "        \"\"\"\n",
    "        Предсказание на входных данных.\n",
    "\n",
    "        :param x: Входные данные (изображения)\n",
    "        :type x: np.ndarray or torch.Tensor\n",
    "        :param postprocess: Флаг постобработки результатов\n",
    "        :type postprocess: bool\n",
    "        :return: Список результатов для каждого изображения, где каждый элемент — словарь с ключами:\n",
    "                 - ``'boxes'``: координаты bounding boxes (форма зависит от `postprocess`)\n",
    "                 - ``'labels'``: метки классов (строки при `postprocess=True`, иначе int)\n",
    "                 - ``'scores'``: оценки уверенности\n",
    "        :rtype: list[dict]\n",
    "\n",
    "        .. note::\n",
    "            - При ``postprocess=True`` возвращаются numpy-массивы и строковые метки.\n",
    "            - При ``postprocess=False`` возвращаются тензоры и целочисленные метки.\n",
    "\n",
    "        Пример возвращаемого значения:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            [\n",
    "                {\n",
    "                    'boxes': np.array([[100, 50, 200, 150], ...]),\n",
    "                    'labels': ['cat', 'dog'],\n",
    "                    'scores': np.array([0.95, 0.87])\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        \"\"\"\n",
    "        self.orig_model.model.eval()\n",
    "        results = self.orig_model(torch.tensor(x), verbose=False)\n",
    "        outputs = []\n",
    "        for result in results:\n",
    "            if postprocess:\n",
    "                # Возвращаем numpy массивы с постобработкой\n",
    "                boxes = result.boxes.xyxy.numpy()\n",
    "                scores = result.boxes.conf.numpy()\n",
    "                labels = [result.names.get(int(l), \"unk\") for l in result.boxes.cls]\n",
    "            else:\n",
    "                # Возвращаем тензоры без постобработки\n",
    "                boxes = result.boxes.xyxy\n",
    "                scores = result.boxes.conf\n",
    "                labels = result.boxes.cls.int()\n",
    "\n",
    "            outputs.append({\n",
    "                'boxes': boxes,\n",
    "                'labels': labels,\n",
    "                'scores': scores\n",
    "            })\n",
    "        return outputs\n",
    "\n",
    "    def train(self, state=True):\n",
    "        \"\"\"\n",
    "        Установка режима обучения/оценки.\n",
    "\n",
    "        :param state: Флаг режима:\n",
    "                      - ``True``: режим обучения\n",
    "                      - ``False``: режим оценки\n",
    "        :type state: bool\n",
    "\n",
    "        .. note::\n",
    "            Метод также устанавливает внутреннее состояние ``self.training``.\n",
    "            Параметры модели заморожены, поэтому обучение не изменяет веса.\n",
    "\n",
    "        Пример:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            wrapper.train(True)   # Перевод в режим обучения\n",
    "            wrapper.train(False)  # Перевод в режим оценки\n",
    "        \"\"\"\n",
    "        self.model.train() if state else self.model.eval()\n",
    "        self.training = state"
   ],
   "id": "722faeec00801019",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Создание модели с параметрами",
   "id": "b1e6e79c3d582949"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T19:26:05.426158Z",
     "start_time": "2025-09-06T19:26:04.958691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = YOLO('yolo11s.pt').to(torch.device('cuda'))\n",
    "detector = YoloWrapper(model)\n",
    "cls = PyTorchYolo(detector,\n",
    "                  input_shape=(3,640,640),\n",
    "                  clip_values=(0,1),\n",
    "                  attack_losses=('loss_cls',\n",
    "                                 'loss_box',\n",
    "                                 'loss_dfl'))"
   ],
   "id": "d832cd2cd2a930db",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Проведение атаки с параметрами",
   "id": "76863914543e493c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T19:26:05.475857Z",
     "start_time": "2025-09-06T19:26:05.470075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "atk = RobustDPatch(\n",
    "    cls,\n",
    "    patch_shape=(3, 160, 160),\n",
    "    patch_location=(0,0),\n",
    "    crop_range=(0,0),\n",
    "    brightness_range=(0.7, 1.0),\n",
    "    rotation_weights=(1,0,0,0),\n",
    "    sample_size=1,\n",
    "    max_iter=1000,\n",
    "    learning_rate=0.05,\n",
    "    batch_size=3,\n",
    "    targeted=False,\n",
    "    verbose=True,\n",
    ")"
   ],
   "id": "d3391d1b049c89fb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:58:46.161528Z",
     "start_time": "2025-09-06T19:26:05.551648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "patch = atk.generate(x=x)\n",
    "save_patch(patch, '0609_yolo_dpatch_1000.png')"
   ],
   "id": "e5b7796e792b100a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustDPatch iteration:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "168d2dfb35af4b8bb5faa71e2cdc1a7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T18:06:55.174827333Z",
     "start_time": "2025-09-03T18:53:11.209747Z"
    }
   },
   "cell_type": "code",
   "source": "x.shape",
   "id": "c446363286b12004",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 3, 640, 640)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T18:06:55.463392369Z",
     "start_time": "2025-09-03T16:45:33.984866Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "ed05b7e23dc35a54",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
